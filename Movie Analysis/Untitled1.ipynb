{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class ImageProcessing:\n",
    "    \n",
    "    def image_process(self):\n",
    "        import pytesseract\n",
    "        from PIL import Image\n",
    "        import cv2\n",
    "        import os\n",
    "        path='c:\\data_analysis'\n",
    "        # load the image \n",
    "        img_path=input(\"Enter the complete path of the image file\")\n",
    "        img=Image.open(img_path)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        print(\"Hold until we process your Image.....\")\n",
    "        #convert the image type into numpy array for processing\n",
    "        image_data = np.asarray(img)\n",
    "        #denoising the image\n",
    "        dst = cv2.fastNlMeansDenoisingColored(image_data,None,10,10,7,21)\n",
    "        #saving the denoised image\n",
    "        cv2.imwrite(r'c:\\data_analysis\\deionise.png', dst)\n",
    "        #to convert tesseract_cmd file to tesseract.exe\n",
    "        pytesseract.pytesseract.tesseract_cmd = \"C:/Program Files/Tesseract 4.0.0/tesseract.exe\"\n",
    "        pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "        #converting the image into grayscale\n",
    "        gray = cv2.cvtColor(image_data, cv2.COLOR_BGR2GRAY)\n",
    "        #saving the grayscale image\n",
    "        cv2.imwrite(r'c:\\data_analysis\\enhancedGrayscaleLineCapture.png', gray)\n",
    "        #to increase the threshold of the image\n",
    "        th1 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                                    cv2.THRESH_BINARY,11,2)\n",
    "        ret2,th2 = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "        ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        blue, green, red = cv2.split(image_data)\n",
    "        blue_edges = cv2.Canny(blue, 100, 10)       \n",
    "        green_edges = cv2.Canny(green, 100, 10)\n",
    "        red_edges = cv2.Canny(red, 100, 10)\n",
    "        edges = blue_edges | green_edges | red_edges\n",
    "        #saving enhanced gray scale threshold,grayscaled images\n",
    "        cv2.imwrite(r'c:\\data_analysis\\enhancedGrayscaleThresholdLineCapture.png', th2)\n",
    "        cv2.imwrite(r'c:\\data_analysis\\bluegreenred.png', edges)\n",
    "        img2=Image.open(r'c:\\data_analysis\\enhancedGrayscaleThresholdLineCapture.png')\n",
    "        img1=Image.open(r'c:\\data_analysis\\bluegreenred.png')\n",
    "        images=Image.open(r'c:\\data_analysis\\deionise.png')\n",
    "        #extract text from denoised image\n",
    "        result=pytesseract.image_to_string(images,lang='eng')\n",
    "        output_temp=result.split()\n",
    "        for i in range(len(output_temp)):\n",
    "            output_temp[i]=output_temp[i].lower()\n",
    "        output_vectors=[]\n",
    "        \"\"\"for i in range(len(output_temp)):\n",
    "            output_vectors.append(len(output_temp[i]))\n",
    "        x=max(output_vectors)\n",
    "        for k in range(len(output_vectors)):\n",
    "            if(x==output_vectors[k]):\n",
    "                x=k\n",
    "                break\n",
    "        output=output_temp[x]\"\"\"\n",
    "        return output_temp    \n",
    "\n",
    "\n",
    "class NLP:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output_vectors=[]\n",
    "        self.input_text_vectors=[]\n",
    "        self.constraints_vectors=[]\n",
    "        self.keywords_vectors=[]\n",
    "        self.output=[]\n",
    "        self.num_words=1000\n",
    "        self.number_of_constraints=0\n",
    "        ck = pd.read_csv(\"./const_key.csv\")  #ck.iloc[:, 0]\n",
    "        self.keywords=ck.iloc[0:3, 1].tolist()\n",
    "        self.constraints = (ck.iloc[:, 0]).tolist()\n",
    "        self.input_text = \"\"\n",
    "        self.temp =[]\n",
    "        self.key_count = 0\n",
    "        \n",
    "    def input_query(self):\n",
    "        self.input_text=input(\"Enter Your Query:\\n\")\n",
    "        \n",
    "    def processing(self):\n",
    "        self.temp=(self.input_text).split(\" \")\n",
    "        l1=self.temp+self.constraints+self.keywords\n",
    "        l = [l1]\n",
    "        tokenizer=Tokenizer(num_words=self.num_words)\n",
    "        tokenizer.fit_on_texts(l)\n",
    "        token_outputs=tokenizer.word_index\n",
    "        for i in range(len(self.temp)):\n",
    "            self.input_text_vectors.append(token_outputs[self.temp[i]])\n",
    "        for j in range(len(self.constraints)):\n",
    "            self.constraints_vectors.append(token_outputs[self.constraints[j]])\n",
    "        for k in range(len(self.keywords)):\n",
    "            self.keywords_vectors.append(token_outputs[self.keywords[k]])\n",
    "        for m in range(len(self.input_text_vectors)):\n",
    "            for n in range(len(self.constraints_vectors)):\n",
    "                if(self.input_text_vectors[m]==self.constraints_vectors[n]):\n",
    "                    self.output_vectors.append(self.input_text_vectors[m])\n",
    "                    self.number_of_constraints+=1\n",
    "        for o in range(len(self.input_text_vectors)):\n",
    "            for p in range(len(self.keywords_vectors)):\n",
    "                if(self.input_text_vectors[o]==self.keywords_vectors[p]):#must handle array index out of bound error and print query incomplete\n",
    "                    try:\n",
    "                        self.key_count += 1\n",
    "                        self.output_vectors.append(self.input_text_vectors[o+1])\n",
    "                    except IndexError as e:\n",
    "                        print(\"Query does not contain enough parameters.\")\n",
    "                        return self.processing()\n",
    "        self.output.append(self.number_of_constraints)\n",
    "        for q in range(len(self.output_vectors)):\n",
    "            for value,vectors in token_outputs.items():\n",
    "                if (self.output_vectors[q]==vectors):\n",
    "                    self.output.append(value)\n",
    "        if 'predict' in self.output:\n",
    "            return self.output\n",
    "        if self.number_of_constraints <= self.key_count:\n",
    "            return self.output\n",
    "        else:\n",
    "            print(\"Not enough keywords\")\n",
    "            self.input_query()\n",
    "\n",
    "class Visualize:\n",
    "    def __init__(self):\n",
    "        self.df1 = pd.read_csv('./movie_name_char_mentions_centrality.csv')\n",
    "        self.df2 = pd.read_csv('./movie_emotion_year.csv')\n",
    "        self.df3 = pd.read_csv('./movie_singer_count.csv')\n",
    "        self.df4 = pd.read_csv('./movie_plot.csv')\n",
    "        self.df5 = pd.read_csv('./movie_all.csv')\n",
    "        \n",
    "    def lead_role(self, q):\n",
    "        col = self.df1[self.df1['movie']==q]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", q, \" is not found in the database. Cannot find the lead role\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        result = 'actor' in ser.values\n",
    "        if(result):\n",
    "            print(\"The lead role is 'actor'\")\n",
    "            print(\"The type of role played is: \", col[col['name'].values=='actor']['character'])\n",
    "            \n",
    "        else:\n",
    "            col = col.sort_values(by=['count'], ascending=False)\n",
    "            ser = col['name']\n",
    "            nam = ser.values[0]\n",
    "            ind = ser[ser==nam].index[0]\n",
    "            print(\"The lead role is:\", nam)\n",
    "            print(\"The type of role played is: \", self.df1[self.df1['index']==ind]['character'].values[0])\n",
    "            \n",
    "    def characters(self, q):\n",
    "        col = self.df1[self.df1['movie']==q]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", q, \" is not found in the database. Cannot find the characters\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        print(\"The characters in the movies\", q, \"include:\")\n",
    "        print(col[['name', 'character']])\n",
    "        \n",
    "    def character(self, q, m):\n",
    "        col = self.df1[self.df1['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Cannot find the character\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        nam = \"NULL\"\n",
    "        try:\n",
    "            nam = ser[ser==q].values[0]\n",
    "        except IndexError as e:\n",
    "            print(\"The character \", q, \" is not found in the database.Cannot find the character.\", sep=\"\")\n",
    "            return\n",
    "        ind = ser[ser==nam].index[0]\n",
    "        print(\"The role is:\", nam)\n",
    "        print(\"The type of role played is: \", self.df1[self.df1['index']==ind]['character'].values[0])\n",
    "        \n",
    "    def plot(self, m):\n",
    "        pd.set_option('display.max_colwidth', -1)\n",
    "        col = self.df4[self.df4['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Cannot find the plot of the movie\", sep=\"\")\n",
    "            return\n",
    "        print(\"The plot of the film goes like: \")\n",
    "        print(col['plot'])\n",
    "        \n",
    "    def appearances(self, c, m):\n",
    "        col = self.df1[self.df1['movie'] == m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Cannot find appearances.\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        try:\n",
    "            nam = ser[ser==c].values[0]\n",
    "        except IndexError as e:\n",
    "            print(\"The character \", c, \" is not found in the database.Cannot find the appearances.\", sep=\"\")\n",
    "            return\n",
    "        ind = ser[ser==nam].index[0]\n",
    "        print(\"The role is:\", nam)\n",
    "        print(\"The number of appearances are: \", self.df1[self.df1['index']==ind]['count'].values[0])\n",
    "        print(\"The average centrality is: \", self.df1[self.df1['index']==ind]['average centrality'].values[0])\n",
    "        print(\"The total centrality is: \", self.df1[self.df1['index']==ind]['total centrality'].values[0])\n",
    "       \n",
    "        \n",
    "    def year(self, m):\n",
    "        col = self.df2[self.df2['movie'] == m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Cannot find the year of release.\", sep=\"\")\n",
    "            return\n",
    "        print(\"The movie\", m, \"released in the year\",col['year'].values[0])\n",
    "        \n",
    "    def songs(self, m):\n",
    "        col = self.df3[self.df3['movie'] == m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Cannot find the songs data.\", sep=\"\")\n",
    "            return\n",
    "        singers = col['singer_name'].values.tolist()\n",
    "        print(\"The movie\", m, \"has\", col['song_count'].sum(), \"songs.\\n\")\n",
    "        print(\"And the singers are:\\n\", \"\\n \".join(singers))\n",
    "        \n",
    "    def average_emotion(self, m, n):\n",
    "        col = self.df2[self.df2['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Cannot find average emotion.\", sep=\"\")\n",
    "            return\n",
    "        se = col['emotion'].value_counts()\n",
    "        if(n==0):\n",
    "            fig, ax = plt.subplots(figsize=(12, 6), subplot_kw=dict(aspect=\"equal\"))\n",
    "            recipe = se.index\n",
    "            data = se.values\n",
    "            wedges, texts = ax.pie(data, wedgeprops=dict(width=0.5), startangle=-40)\n",
    "            bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "            kw = dict(xycoords='data', textcoords='data', arrowprops=dict(arrowstyle=\"-\"),\n",
    "                      bbox=bbox_props, zorder=0, va=\"center\")\n",
    "            for i, p in enumerate(wedges):\n",
    "                ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "                y = np.sin(np.deg2rad(ang))\n",
    "                x = np.cos(np.deg2rad(ang))\n",
    "                horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "                connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n",
    "                kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
    "                ax.annotate(recipe[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),horizontalalignment=horizontalalignment, **kw)\n",
    "            ax.set_title(\"Average Emotion\")\n",
    "        \n",
    "            plt.show()\n",
    "        \n",
    "        maxi = max(se.values)\n",
    "        mini = min(se.values)\n",
    "        max_per = (maxi/sum(se.values))*100\n",
    "        min_per = (mini/sum(se.values))*100\n",
    "        if(n==2):\n",
    "            print('\\nThe most expressed emotion in the film is \"',se[se == maxi].index[0],'\"',\" and constitutes to \", max_per,\"%\",sep=\"\")\n",
    "        if(n==1):\n",
    "            print('\\nThe least expressed emotion in the film is \"',se[se == mini].index[0],'\"',\" and constitutes to \", min_per,\"%\", sep=\"\")\n",
    "       \n",
    "        # creating word cloud\n",
    "        if(n==0):\n",
    "            self.create_wordcloud(col)\n",
    "        \n",
    "        if(n==0):\n",
    "            # genre of the film\n",
    "            self.genre(m)\n",
    "        \n",
    "    def create_wordcloud(self, q):\n",
    "        from wordcloud import WordCloud, STOPWORDS \n",
    "        print(\"\\n\\nThe wordcloud created for the emotions of the data in the film:\\n\")\n",
    "        comment_words = ' '\n",
    "        stopwords = set(STOPWORDS) \n",
    "\n",
    "        for val in q: \n",
    "            val = str(val) \n",
    "            tokens = val.split()  \n",
    "            for i in range(len(tokens)): \n",
    "                tokens[i] = tokens[i].lower() \n",
    "\n",
    "            for words in tokens: \n",
    "                comment_words = comment_words + words + ' '\n",
    "\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800, \n",
    "                        background_color ='white', \n",
    "                        stopwords = stopwords, \n",
    "                        min_font_size = 10).generate(' '.join(q['emotion'])) \n",
    "\n",
    "        plt.figure(figsize = (4, 4), facecolor = None) \n",
    "        plt.imshow(wordcloud) \n",
    "        plt.axis(\"off\") \n",
    "        plt.tight_layout(pad = 0) \n",
    "        plt.show()\n",
    "        print(\"Note: The the size of the word increases with higher expressed emotion.\")\n",
    "        \n",
    "    def genre(self, m):\n",
    "        col = self.df2[self.df2['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Cannot find the genre.\", sep=\"\")\n",
    "            return\n",
    "        se = col['emotion'].value_counts()\n",
    "        gen = se[se == max(se.values)].index[0]\n",
    "        \n",
    "        #fuzzying the output\n",
    "        \n",
    "        if(gen==\"happy\"):\n",
    "            genre = \"Family-Entertainer\"\n",
    "        elif(gen == \"neutral\"):\n",
    "            genre = \"Drama\"\n",
    "        elif(gen == \"sad\"):\n",
    "            genre = \"Melo-Drama\"\n",
    "        elif(gen == \"angry\"):\n",
    "            genre = \"Action\"\n",
    "        elif(gen == \"fear\"):\n",
    "            genre = \"Horror\"\n",
    "        elif(gen==\"suprise\"):\n",
    "            genre = \"Suspence Thriller\"\n",
    "        elif(gen==\"disgust\"):\n",
    "            genre = \"Crime-Thriller\"\n",
    "        print(\"GENRE:\")\n",
    "        print(\"The movie \", m, \" is a \", genre, \" genre film.\", sep=\"\")\n",
    "        \n",
    "    def length_of_movie(self, m):\n",
    "        col = self.df1[self.df1['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Cannot find the length of the movie\", sep=\"\")\n",
    "            return\n",
    "        se1 = col['mentions'].sum()\n",
    "        se2 = col['count'].sum()\n",
    "        se3 = col['total centrality'].sum()\n",
    "        se4 = col['average centrality'].sum()\n",
    "        result = se1 + (se3/se2) + se4                               # creating an estimation variable\n",
    "        est_time = 150\n",
    "        est_result = 70\n",
    "        if(35<result<est_result):                                    # fuzzyfying the result into time or length of movie\n",
    "            length = est_time\n",
    "        elif(30<result<est_result/2):\n",
    "            length = est_time-20\n",
    "        elif(70<result<est_result*2):\n",
    "            length = est_time+20\n",
    "        elif(140<result<est_result*4):\n",
    "            length = est_time+10\n",
    "        else:\n",
    "            length = est_time - 10\n",
    "        print(\"The predicted length of movie \", m, \" on the basis of Centrality and Mentions is about \", np.round((length/60), 2),sep=\"\")\n",
    "\n",
    "    def trends(self, bol):\n",
    "        df = {}\n",
    "        for i in range(10):\n",
    "            df[i] = self.df2[self.df2['year']==2008+i]['emotion'].value_counts().to_frame()\n",
    "            df[i].columns = [2008+i]\n",
    "        df_area = pd.concat([df[0], df[1], df[2], df[3], df[4], df[5], df[6], df[7],df[8], df[9]], axis=1)\n",
    "        if(bol):\n",
    "            print(df_area)\n",
    "            df_area.transpose().plot.area()\n",
    "            plt.xlabel(\"Year\")\n",
    "            plt.ylabel(\"Range\")\n",
    "            plt.show()\n",
    "            plt.show()\n",
    "        else:\n",
    "            return df_area\n",
    "        \n",
    "    def predict(self):\n",
    "        df_area = self.trends(False)\n",
    "        print(df_area)\n",
    "        # Data-Preprocessing\n",
    "        z = pd.read_csv('./trend_emotion.csv')\n",
    "        X = z.iloc[:, :-1]\n",
    "        y = z.iloc[:, -1]\n",
    "        # Spliting Data \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        # Linear Regression\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X_train, y_train)\n",
    "        predictions_lin = lm.predict(X_test)\n",
    "       \n",
    "        # Calculating the Result in terms of errors\n",
    "        from sklearn import metrics\n",
    "        result = list()\n",
    "        result.append(metrics.mean_squared_error(y_test, predictions_lin))\n",
    "        result = np.array(result)\n",
    "        new = list()\n",
    "        emotions = ['angry', 'disgust', 'fear', 'happy', 'neurtal', 'sad', 'suprise']\n",
    "        print(\"\\n\")\n",
    "        for i in range(7):\n",
    "            print(\"Enter value of\",emotions[i],\":\", end=\"\")\n",
    "            new.append(int(input()))\n",
    "        result = lm.predict([new])\n",
    "        print(\"\\nThe predicted year according the values given is \",result[0])\n",
    "        \n",
    "    def image_movie(self, arr):\n",
    "        for i in range(len(arr)):\n",
    "            if arr[i] in self.df5.iloc[:, -1].values:\n",
    "                m = arr[i]\n",
    "                self.lead_role(m)\n",
    "                self.characters(m)\n",
    "                self.plot(m)\n",
    "                self.year(m)\n",
    "                self.songs(m)\n",
    "                self.average_emotion(m, 0)\n",
    "                self.length_of_movie(m)\n",
    "                return\n",
    "        print(\"Could not find the movie in the dataset. Try another image.\")\n",
    "        \n",
    "\n",
    "# Driver Code\n",
    "\n",
    "# input using NLP\n",
    "ext = 0         # checking for exit condition  \n",
    "while ext!=1:\n",
    "    obj = Visualize()\n",
    "    print(\"\\n\")\n",
    "    choice = int(input(\"Enter your choice:\\n1.Image Input\\n2.Text Input\\n3.Exit\\n\"))\n",
    "    if choice == 1:\n",
    "        ob = ImageProcessing()\n",
    "        tensor = ob.image_process()\n",
    "        obj.image_movie(tensor)\n",
    "        continue\n",
    "    elif choice == 2:\n",
    "        print(\"Queries can be framed using the following to get optimum results:\")\n",
    "        print(\"1.characters\\n2.plot\\n3.genre\\n4.attitude\\n5.appearances\\n6.year\\n7.songs\\n8.length\\n9.variation\\n10.predict\\n11.emotion\\n12.role\\n13.exit\\n14.movie\\n15.emotions\\n16.character\\n\")\n",
    "        ob = NLP()\n",
    "        ob.input_query()\n",
    "        tensor = ob.processing()\n",
    "    elif choice == 3:\n",
    "        print(\"Interupt Process\")\n",
    "        break;\n",
    "    else:\n",
    "        print(\"Invalid Input\")\n",
    "        continue\n",
    "    # Visualizing the queries\n",
    "    \n",
    "    count = tensor[0]\n",
    "    for i in range(1, tensor[0]+1):\n",
    "        \n",
    "        if tensor[i]==\"role\":\n",
    "            obj.lead_role(tensor[i + count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"characters\":\n",
    "            obj.characters(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"attitude\":\n",
    "            obj.character(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"plot\":\n",
    "            obj.plot(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"appearances\":\n",
    "            obj.appearances(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"year\":\n",
    "            obj.year(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"songs\":\n",
    "            obj.songs(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"emotion\":\n",
    "            try:\n",
    "                if (\"average\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 0)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"minor\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 1)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"major\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 2)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif(\"predict\" in ob.temp):\n",
    "                    obj.predict()\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "            except IndexError as e:\n",
    "                print(\"Not enough parameters\")\n",
    "                break\n",
    "        \n",
    "        elif tensor[i]==\"genre\":\n",
    "            obj.genre(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"length\":\n",
    "            obj.length_of_movie(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "\n",
    "        elif tensor[i]==\"variation\":\n",
    "            obj.trends(True)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            \n",
    "        elif tensor[i]==\"exit\":\n",
    "            print(\"Process Interupt\")\n",
    "            ext = 1\n",
    "        else:\n",
    "            print(\"Query does not contain enough parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what is the variation in movie s year-wise and what is the genre of the movie  3 idiots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
